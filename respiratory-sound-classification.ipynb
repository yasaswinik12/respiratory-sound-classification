{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n\nimport wavio\nimport librosa\nimport librosa.display\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport time\nfrom random import shuffle\n\n# Data Visualizatoin\nimport matplotlib.pyplot as plt\n# %matplotlib inline\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n #       print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-18T12:17:35.991133Z","iopub.execute_input":"2022-01-18T12:17:35.992354Z","iopub.status.idle":"2022-01-18T12:17:38.243056Z","shell.execute_reply.started":"2022-01-18T12:17:35.992204Z","shell.execute_reply":"2022-01-18T12:17:38.242202Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/respiratory_sound_database'\n\ndemogr_fname = '../input/respiratory-sound-database/demographic_info.txt'\ndemogrCol_strLst = ['Patient number', 'Age', 'Sex' , 'Adult BMI (kg/m2)', 'Child Weight (kg)' , 'Child Height (cm)']\ndemogr_df = pd.read_csv(\n    demogr_fname, \n    names = demogrCol_strLst,\n    delimiter = ' ',\n)\n\ndemogr_fname = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv'\ndiagnosisCol_strLst = ['Patient number', 'Diagnosis']\ndiagnosis_df = pd.read_csv(\n    demogr_fname,\n    names = diagnosisCol_strLst,\n)\n\ndata_dname = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'\nrecords_idLst = [s.split('.')[0] for s in os.listdir(path = data_dname) if '.txt' in s]\n\nprint(\"# Of recordings: %d\"%(len(records_idLst)))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:17:40.948540Z","iopub.execute_input":"2022-01-18T12:17:40.949071Z","iopub.status.idle":"2022-01-18T12:17:41.006323Z","shell.execute_reply.started":"2022-01-18T12:17:40.949024Z","shell.execute_reply":"2022-01-18T12:17:41.005687Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def loadData(record_id, dry = False):\n    \n    data_fname = record_id + '.wav'\n    annotation_fname = record_id + '.txt'\n    \n    if not dry:\n        wave_data = wavio.read(data_dname+'/'+data_fname)\n        waveform_np = wave_data.data.astype(float).flatten()\n        waveWidth_int= wave_data.sampwidth\n\n        # Get the info of the wavefile\n        fs = wave_data.rate # Sampling frequency\n        N = waveform_np.shape[0]\n        \n    else:\n        waveform_np = None\n        fs = float('nan')\n        N = float('nan')\n    Ts = 1.0 / fs;\n    AT = Ts * N    \n\n    tokens_strLst = record_id.split('_') + [fs, N, AT, Ts]\n    \n    infoLabels_strLst = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment', 'fs', 'N', 'AT', 'Ts']\n    recordInfo_dict = dict(zip(infoLabels_strLst,tokens_strLst))\n    \n    dataCols_strLst = ['Start', 'End', 'Crackles', 'Wheezes']\n    recAnnotations_df = pd.read_csv(\n        os.path.join(data_dname, annotation_fname), \n        names = dataCols_strLst,\n        delimiter= '\\t'\n    )\n    \n    return (waveform_np, recordInfo_dict, recAnnotations_df)\n\n(waveform_np, recordInfo_dict, recAnnotations_df) = loadData(records_idLst[0], 0)\n_, recordInfo_dict, recAnnotations_df = loadData(records_idLst[0], 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:19:19.787773Z","iopub.execute_input":"2022-01-18T12:19:19.788553Z","iopub.status.idle":"2022-01-18T12:19:19.890999Z","shell.execute_reply.started":"2022-01-18T12:19:19.788507Z","shell.execute_reply":"2022-01-18T12:19:19.890191Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Class to time the execution blocks\nclass Timer():\n    # Static variable for verbosity\n    quiet = False\n    \n    # Init the class\n    def __init__(self, str): \n        # print('init method called') \n        self.str = str\n        \n    # Enter the context\n    def __enter__(self):\n        # print('enter method called') \n        self.tick = time.time()\n        return self\n    \n    # Leave the context\n    def __exit__(self, exc_type, exc_value, exc_traceback): \n        if not Timer.quiet:\n            print(\"%s: \\t%.3f s\"%(self.str, time.time() - self.tick))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:19:25.291568Z","iopub.execute_input":"2022-01-18T12:19:25.291911Z","iopub.status.idle":"2022-01-18T12:19:25.298173Z","shell.execute_reply.started":"2022-01-18T12:19:25.291876Z","shell.execute_reply":"2022-01-18T12:19:25.296664Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Distribution of respiratory cycle lengths\n\nrespDuration_ser = pd.Series([],dtype='float64')\nfor record_id in records_idLst:\n    _, recordInfo_dict, recAnnotations_df = loadData(record_id, dry = True)\n    respDuration_ser = respDuration_ser.append(recAnnotations_df['End'] - recAnnotations_df['Start'])\n\nplt.figure(figsize=(16,16))\nrespDuration_ser.hist(bins=50)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:19:39.267264Z","iopub.execute_input":"2022-01-18T12:19:39.268168Z","iopub.status.idle":"2022-01-18T12:19:45.987969Z","shell.execute_reply.started":"2022-01-18T12:19:39.268101Z","shell.execute_reply":"2022-01-18T12:19:45.987352Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Feature extraction\n\n# Parameters\nframeLength_int = 2**13\nframeHop_int = 2**11\n\n# Derivative values\nframeOvelap_int = frameLength_int - frameHop_int\n\ndef extractFeatures(waveform_np, recordInfo_dict, dry=False):\n    \n    if dry:\n        # Extract the spectrum from the waveform\n        spectrum_np = librosa.core.stft(\n           waveform_np, \n           n_fft=frameLength_int, \n           hop_length=frameHop_int, \n           win_length=frameLength_int, \n        )\n        spectrumMag_np = np.abs(spectrum_np)\n        spectrumN_int = spectrumMag_np.shape[1]\n        spectrumTime_np = np.linspace(0,recordInfo_dict['AT'],spectrumN_int)\n    else:\n        # Chroma Frequencies\n        chroma_np = librosa.feature.chroma_stft(\n            waveform_np, \n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n        # Spectral Centroid\n        spectralCentroid_np = librosa.feature.spectral_centroid(\n            waveform_np,\n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n        # Spectral Bandwidth\n        spectralBandwidth_np = librosa.feature.spectral_bandwidth(\n            waveform_np, \n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n        # Spectral Roll-off\n        spectralRolloff_np = librosa.feature.spectral_rolloff(\n            waveform_np,\n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n        # Zero Crossing Rate\n        spectralZeroCrossing_zp = librosa.feature.zero_crossing_rate(\n            waveform_np,\n            hop_length=frameHop_int, \n            frame_length=frameLength_int, \n        )\n\n        # Mel Cepstral Coeffs (MFCC)\n        mfcc_np = librosa.feature.mfcc(\n            waveform_np,\n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n    features_np = np.concatenate((\n#        spectrumMag_np,\n        spectralCentroid_np,\n        spectralBandwidth_np,\n        spectralRolloff_np,\n        spectralZeroCrossing_zp,\n#        chroma_np,\n        mfcc_np,\n    )).T\n    \n    \n    \n    scaler = preprocessing.StandardScaler()\n    #scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n    features_np = scaler.fit_transform(features_np)\n        \n    return features_np\n\n\n(waveform_np, recordInfo_dict, recAnnotations_df) = loadData(records_idLst[0])\nfeatures_np = extractFeatures(waveform_np, recordInfo_dict)\n\nprint(features_np.shape)\nprint(features_np.min(axis=0))\nprint(features_np.mean(axis=0))\nprint(features_np.max(axis=0))\nprint(features_np.std(axis=0))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:21:02.380719Z","iopub.execute_input":"2022-01-18T12:21:02.381013Z","iopub.status.idle":"2022-01-18T12:21:03.146350Z","shell.execute_reply.started":"2022-01-18T12:21:02.380982Z","shell.execute_reply":"2022-01-18T12:21:03.145180Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"spectrum_np = librosa.core.stft(\n   waveform_np, \n   n_fft=frameLength_int, \n   hop_length=frameHop_int, \n   win_length=frameLength_int, \n)\nspectrumMagLog_np = np.log(np.abs(spectrum_np))\nspectrumN_int = spectrumMagLog_np.shape[1]\nspectrumTime_np = np.linspace(0,recordInfo_dict['AT'],spectrumN_int)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:22:35.756512Z","iopub.execute_input":"2022-01-18T12:22:35.757343Z","iopub.status.idle":"2022-01-18T12:22:35.855022Z","shell.execute_reply.started":"2022-01-18T12:22:35.757295Z","shell.execute_reply":"2022-01-18T12:22:35.854006Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Convert the annotations to a usable Y vector\n# TODO: Perhaps we can use a complex periodic signal i.e. 2 output vectors\n\ndef annotations2Y(recAnnotations_df, recordInfo_dict):\n\n    # Variables\n    t = spectrumTime_np\n    Y = np.zeros(t.shape[0])\n    lag_f = 0\n    \n    for row in recAnnotations_df.itertuples():\n        start_f = row.Start\n        stop_f = row.End\n        duration_f = stop_f - start_f\n        mask_b = np.logical_and(t >= start_f, t < stop_f)\n        x = 0.5 - np.cos(2*np.pi*(t-stop_f)/duration_f)/2\n        \n        Y[mask_b] = x[mask_b]\n        \n    return t,Y\n\nt_np, Y_np = annotations2Y(recAnnotations_df, recordInfo_dict)\n\nprint(spectrumMagLog_np.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:24:26.792295Z","iopub.execute_input":"2022-01-18T12:24:26.792832Z","iopub.status.idle":"2022-01-18T12:24:26.801693Z","shell.execute_reply.started":"2022-01-18T12:24:26.792792Z","shell.execute_reply":"2022-01-18T12:24:26.800740Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def generateDataset(records_idLst):\n    \n    records_cnt = len(records_idLst)\n    \n    # This function takes time so lets do some reporting\n    print(\"Generating a dataset of %d records\"%(records_cnt))\n    \n    datasetX_np = None\n    datasetY_np = None\n    for index_int, record_id in enumerate(records_idLst):\n        \n        # Load the file\n        (waveform_np, recordInfo_dict, recAnnotations_df) = loadData(records_idLst[0])\n\n        # Extract the features\n        features_np = extractFeatures(waveform_np, recordInfo_dict, )\n\n        # Extract the target\n        t_np, Y_np = annotations2Y(recAnnotations_df, recordInfo_dict)\n\n        if datasetX_np is None:\n            datasetX_np = features_np\n            datasetY_np = Y_np\n        else:\n            datasetX_np = np.append(datasetX_np, features_np, axis=0)\n            datasetY_np = np.append(datasetY_np, Y_np)\n        print(\"Loading: %5.2f%%\\t%s\"%(100.0 * (index_int + 1) / records_cnt, record_id), end=\"\\r\")\n        \n    print(\"\")\n    print(datasetX_np.shape)\n    print(datasetY_np.shape)\n    return datasetX_np, datasetY_np","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:24:31.504543Z","iopub.execute_input":"2022-01-18T12:24:31.505347Z","iopub.status.idle":"2022-01-18T12:24:31.512051Z","shell.execute_reply.started":"2022-01-18T12:24:31.505304Z","shell.execute_reply":"2022-01-18T12:24:31.511417Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Parameters\ntestN_cnt = 10\n\n# Randomize the dataset order\nshuffle(records_idLst)\n# Split the training and test datasets\ntrainRecords_idLst = records_idLst[testN_cnt:]\ntestRecords_idLst = records_idLst[:testN_cnt]","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:24:40.491161Z","iopub.execute_input":"2022-01-18T12:24:40.491711Z","iopub.status.idle":"2022-01-18T12:24:40.496193Z","shell.execute_reply.started":"2022-01-18T12:24:40.491674Z","shell.execute_reply":"2022-01-18T12:24:40.495566Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def evaluateModel(model):\n    \n    trainR2_f = model.score(trainX_np, trainY_np)\n    testR2_f = model.score(testX_np, testY_np)\n    print(\"Train R2: %8.5f\\t Test R2: %8.5f\\t (%5.2f)\"%(trainR2_f,testR2_f,testR2_f/trainR2_f))\n\n    trainResult_np = model.predict(trainX_np)\n    testResult_np = model.predict(testX_np)\n    visualResult_np = model.predict(visualX_np)\n\n    trainMAE_f = metrics.mean_absolute_error(trainY_np, trainResult_np)\n    testMAE_f = metrics.mean_absolute_error(testY_np, testResult_np)\n    print(\"Train MAE: %8.5f\\t Test MAE: %8.5f\\t (%5.2f)\"%(trainMAE_f,testMAE_f,testMAE_f/trainMAE_f))\n\n    # Visualize the test performance\n    visualX_np, visualY_np\n\n    plt.figure(figsize=(24,10))\n    \n    plt.subplot(211)\n    plt.plot(trainY_np[:visualN_cnt],'g')\n    plt.plot(trainResult_np[:visualN_cnt],'b.')\n    plt.title('Training Set fit')\n    \n    plt.subplot(212)\n    plt.plot(visualY_np,'g')\n    plt.plot(visualResult_np,'b.')\n    plt.title('Test Set fit')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:24:43.286986Z","iopub.execute_input":"2022-01-18T12:24:43.287560Z","iopub.status.idle":"2022-01-18T12:24:43.294776Z","shell.execute_reply.started":"2022-01-18T12:24:43.287519Z","shell.execute_reply":"2022-01-18T12:24:43.293585Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Create the training dataset\n\nwith Timer(\"Training set generation:\"):\n    trainX_np, trainY_np = generateDataset(trainRecords_idLst)\nprint(\"Training dataset consists of %d records\"%(len(trainRecords_idLst)))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:24:51.596375Z","iopub.execute_input":"2022-01-18T12:24:51.597093Z","iopub.status.idle":"2022-01-18T12:36:58.632262Z","shell.execute_reply.started":"2022-01-18T12:24:51.597047Z","shell.execute_reply":"2022-01-18T12:36:58.630892Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Create the test set\n\ntestX_np, testY_np = generateDataset(testRecords_idLst)\n\nprint(\"Test dataset consists of %d records\"%(len(testRecords_idLst)))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:36:58.635853Z","iopub.execute_input":"2022-01-18T12:36:58.636709Z","iopub.status.idle":"2022-01-18T12:37:06.661409Z","shell.execute_reply.started":"2022-01-18T12:36:58.636612Z","shell.execute_reply":"2022-01-18T12:37:06.660373Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Pick a record from the validation set to do the visualization\n\nrecords_idLst = [testRecords_idLst[0]]\n#records_idLst = [trainRecords_idLst[0]]\n\nvisualX_np, visualY_np = generateDataset(records_idLst)\nvisualN_cnt = visualX_np.shape[0]\n\n(waveform_np, recordInfo_dict, recAnnotations_df) = loadData(records_idLst[0], False)\n\nprint(\"N:\",recordInfo_dict['N'])\nprint(\"AT:\",recordInfo_dict['AT'])\n\nplt.figure(figsize=(24,10))\nplt.subplot(211)\nplt.plot(trainY_np[:visualN_cnt],'g')\nplt.subplot(212)\nplt.plot(visualY_np,'g')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:37:06.663120Z","iopub.execute_input":"2022-01-18T12:37:06.663706Z","iopub.status.idle":"2022-01-18T12:37:07.876820Z","shell.execute_reply.started":"2022-01-18T12:37:06.663639Z","shell.execute_reply":"2022-01-18T12:37:07.876156Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Try Linear Regression\n\nmodel = LinearRegression()\n\nwith Timer(\"Training Linear Regression:\"):\n    model.fit(trainX_np,trainY_np)\n\nevaluateModel(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T06:40:19.537616Z","iopub.execute_input":"2022-01-18T06:40:19.537934Z","iopub.status.idle":"2022-01-18T06:40:20.287811Z","shell.execute_reply.started":"2022-01-18T06:40:19.537907Z","shell.execute_reply":"2022-01-18T06:40:20.287220Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Try Decision Tree Regression\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor(\n    criterion = 'mse',\n#    max_depth = 15,\n)\n\nwith Timer(\"Training Decision Tree Regression:\"):\n    model.fit(trainX_np,trainY_np)\n\n\nevaluateModel(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:37:07.878410Z","iopub.execute_input":"2022-01-18T12:37:07.878773Z","iopub.status.idle":"2022-01-18T12:37:11.098366Z","shell.execute_reply.started":"2022-01-18T12:37:07.878731Z","shell.execute_reply":"2022-01-18T12:37:11.097396Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Try Random Forest Regression\n\nfrom sklearn.ensemble import RandomForestRegressor \n\nmodel = RandomForestRegressor(\n    n_estimators = 30,\n#    max_depth = 10,\n#    min_samples_split = 100,   \n#    random_state = 0,\n) \n\nwith Timer(\"Training Random Forest Regression:\"):\n    model.fit(trainX_np,trainY_np)\n\nevaluateModel(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T12:37:11.099998Z","iopub.execute_input":"2022-01-18T12:37:11.100244Z","iopub.status.idle":"2022-01-18T12:38:07.985500Z","shell.execute_reply.started":"2022-01-18T12:37:11.100213Z","shell.execute_reply":"2022-01-18T12:38:07.984668Z"},"trusted":true},"execution_count":21,"outputs":[]}]}